---
title: "Income Evaluation"
author: "Valencia Lie"
date: "20/07/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem at hand
This report attempts to predict whether someone has an income of over 50k USD or below 50k USD a year based on several parameters:
bout an individual:
- age: the age of an individual
- workclass: a general term to represent the employment status of an individual
- fnlwgt: final weight. In other words, this is the number of people the census believes
the entry represents
- education: the highest level of education achieved by an individual.
- education­num: the highest level of education achieved in numerical form.
- marital­status: marital status of an individual. Married­civ­spouse corresponds to a
civilian spouse while Married­AF­spouse is a spouse in the Armed Forces.
- occupation: the general type of occupation of an individual
- relationship: represents what this individual is relative to others. For example an
individual could be a Husband. Each entry only has one relationship attribute and is
somewhat redundant with marital status. We might not make use of this attribute at all
- race: Descriptions of an individualâ€™s race
- sex: the biological sex of the individual
- capital­gain: capital gains for an individual
- capital­loss: capital loss for an individual
- hours­per­week: the hours an individual has reported to work per week
- native­country: country of origin for an individual
- the label: whether or not an individual makes more than $50,000 annually.

Data set is taken from kaggle.com.

# Structure of report
- Read data and cleansing
- Cross validation
- Check whether data is balanced or not
- Model #1: Naive Bayes
- Predict future data with Naive Bayes
- Model evaluation for Naive Bayes:
  - Disadvantages of Naive Bayes
  - Confusion Matrix
  - ROC/AUC
- Model #2: Decision Tree
- Predict future data with Decision Tree
- Model evaluation for Decision Tree: 
  - Disadvantages of Decision Tree
  - Confusion Matrix
- (possible) Model #3: Random forest:
  - Advantages and how it works
  - Disadvantages
- Tuning final model between Naive Bayes and Decision Tree
- Final conclusion

#Read data and cleansing
```{r}
library(tidyverse)
income <- read_csv("income_evaluation.csv")
```

```{r}
head(income)
anyNA(income)
```

```{r}
income <- income %>% 
  mutate_if(is.character, as.factor) %>% 
  select(-c(relationship, fnlwgt))
income
```

# Cross Validation
```{r}
library(rsample)
set.seed(100)
idx <- initial_split(data = income, prop = 0.8, strata = income )
test <- testing(idx)
train <- training(idx)
```

#Check whether data is balanced or not
```{r}
prop.table(table(income$income))
prop.table(table(test$income))
prop.table(table(train$income))
```

Since it is relatively balanced (not like 90:10 or 95:5), we can move on.

#Model 1: Naive Bayes
```{r}
library(e1071)
model_naive <- naiveBayes(income ~., train)
#no laplace is needed
pred <- predict(model_naive, test, response = "class")
```

# Evaluation of model

## Disadvantages of Naive Bayes model
Naive Bayes are like what its name suggests: naive. Its algorithm thinks that all predictors are independent of each other, which may not always be true. For example, in this data set, there is a column which indicates a person's number of educational years attended as well as their last graduated education degree. Logically, of course we know that someone who graduated with a Master's degree will inevitably have larger number of educational years than someone who graduated with a Bachelor's degree, because in order to graduate with a Master's degree, you need to have a Bachelor's degree first. Hence these predictors are not likely to be completely independent, unlike what this Naive Bayes model had suggested, which may then interfere with our model's reliability in predicting future model.

##Confusion Matrix
```{r}
library(caret)
confusionMatrix(data = pred, reference = test$income, positive = ">50K")
```

From this confusion matrix, we can see that the accuracy of the model in predicting future data is 0.8171, whereas the recall/sensitivity metric is 0.4171 and the precision is 0.7025. 

In this particular problem, it is hard to see which metric is more useful (eg recall or precision) and hence I will merely look into accuracy. This model has achieved a great accuracy (more than 80%), though it has lacked terribly in terms of recall metric and fared okay in terms of precision metric.

##ROC/AUC

